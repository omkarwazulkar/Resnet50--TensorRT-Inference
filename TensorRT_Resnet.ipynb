{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777872ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aws configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f5f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ssh -i \"ColabOmkar3KeyPair.pem\" ec2-user@ec2-98-92-23-236.compute-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76b81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sudo dnf update -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sudo dnf install -y docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c5bc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sudo systemctl start docker\n",
    "%sudo systemctl enable docker\n",
    "%sudo usermod -aG docker ec2-user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cdb164",
   "metadata": {},
   "source": [
    "Exit & SSH again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4755cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%docker --version\n",
    "%docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%docker login nvcr.io\n",
    "%Username: $oauthtoken\n",
    "%Password: <your_token_here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 648758970526.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f057a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%docker pull nvcr.io/nvidia/tensorrt:24.02-py3\n",
    "%docker tag nvcr.io/nvidia/tensorrt:24.02-py3 648758970526.dkr.ecr.us-east-1.amazonaws.com/tensorrt:24.02-py3\n",
    "%docker images | grep tensorrt\n",
    "%docker push 648758970526.dkr.ecr.us-east-1.amazonaws.com/tensorrt:24.02-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6edf54-b277-4c1f-9658-b80343cf768a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.21.0+cu124)\n",
      "Requirement already satisfied: nvidia-ml-py in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (13.580.82)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision nvidia-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2652c-7de0-476d-824e-013bf5338bdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: done\n",
      "Channels:\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.9.1\n",
      "    latest version: 25.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/pytorch_p310\n",
      "\n",
      "  added / updated specs:\n",
      "    - onnx\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2025.10.5-hbd8a1cb_0 --> 2025.11.12-hbd8a1cb_0 \n",
      "  certifi                            2025.10.5-pyhd8ed1ab_0 --> 2025.11.12-pyhd8ed1ab_0 \n",
      "  openssl                                  3.5.4-h26f9b46_0 --> 3.6.0-h26f9b46_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "%conda install -c conda-forge onnx -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daef90dd-27b6-48c2-ab84-6ea084d3591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet ONNX Exported Successfully\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "model.eval()\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"resnet50.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    opset_version=17\n",
    ")\n",
    "\n",
    "print(\"Resnet ONNX Exported Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098cd0b5-96a9-4d4e-808a-4d4ac497eb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing build_resnet50_trt.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile build_resnet50_trt.py\n",
    "import tensorrt as trt\n",
    "import os\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "onnx_path = \"/opt/ml/processing/input/resnet50.onnx\"\n",
    "engine_path = \"/opt/ml/processing/output/resnet50.trt\"\n",
    "\n",
    "print(\"Loading ONNX model:\", onnx_path)\n",
    "\n",
    "trt.init_libnvinfer_plugins(TRT_LOGGER, \"\")\n",
    "\n",
    "with trt.Builder(TRT_LOGGER) as builder, \\\n",
    "     builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)) as network, \\\n",
    "     trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "\n",
    "    config = builder.create_builder_config()\n",
    "\n",
    "    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 2 << 30)\n",
    "\n",
    "    if builder.platform_has_fast_fp16:\n",
    "        config.set_flag(trt.BuilderFlag.FP16)\n",
    "        print(\"FP16 enabled\")\n",
    "\n",
    "    with open(onnx_path, \"rb\") as f:\n",
    "        if not parser.parse(f.read()):\n",
    "            for i in range(parser.num_errors):\n",
    "                print(parser.get_error(i))\n",
    "            raise RuntimeError(\"ONNX parsing failed\")\n",
    "\n",
    "    print(\"Building TensorRT engine...\")\n",
    "    engine_bytes = builder.build_serialized_network(network, config)\n",
    "\n",
    "    if engine_bytes is None:\n",
    "        raise RuntimeError(\"Failed To Build TensorRT Engine\")\n",
    "\n",
    "    with open(engine_path, \"wb\") as f:\n",
    "        f.write(engine_bytes)\n",
    "\n",
    "print(\"ResNet50 TensorRT Engine Built Successfully\")\n",
    "print(\"Saved to:\", engine_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea29175-07d8-4ef6-92bb-138c659b608c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name tensorrt-2025-12-14-01-12-29-276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............\u001b[34m[12/14/2025-01:14:57] [TRT] [I] [MemUsageChange] Init CUDA: CPU +18, GPU +0, now: CPU 25, GPU 253 (MiB)\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:03] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1453, GPU +268, now: CPU 1555, GPU 521 (MiB)\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:03] [TRT] [I] Graph optimization time: 0.22248 seconds.\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:03] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:35] [TRT] [I] Detected 1 inputs and 1 output network tensors.\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [I] Total Host Persistent Memory: 330096\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [I] Total Device Persistent Memory: 5120\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [I] Total Scratch Memory: 0\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 48 MiB, GPU 49 MiB\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 58 steps to complete.\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 0.529102ms to assign 3 blocks to 58 nodes requiring 3612672 bytes.\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [I] Total Activation Memory: 3612672\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [W] TensorRT encountered issues when converting weights between types and that could affect accuracy.\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [W] If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [W] Check verbose logs for the list of affected weights.\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [W] - 57 weights are affected by this issue: Detected subnormal FP16 values.\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [W] - 31 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\u001b[0m\n",
      "\u001b[34m[12/14/2025-01:15:36] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +48, GPU +49, now: CPU 48, GPU 49 (MiB)\u001b[0m\n",
      "\u001b[34mLoading ONNX model: /opt/ml/processing/input/resnet50.onnx\u001b[0m\n",
      "\u001b[34mFP16 enabled\u001b[0m\n",
      "\u001b[34mBuilding TensorRT engine...\u001b[0m\n",
      "\u001b[34mResNet50 TensorRT Engine Built Successfully\u001b[0m\n",
      "\u001b[34mSaved to: /opt/ml/processing/output/resnet50.trt\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "processor = ScriptProcessor(\n",
    "    role=role,\n",
    "    image_uri=\"648758970526.dkr.ecr.us-east-1.amazonaws.com/tensorrt:24.02-py3\",\n",
    "    command=[\"python3\"],\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    volume_size_in_gb=30,\n",
    "    max_runtime_in_seconds=600,\n",
    ")\n",
    "\n",
    "processor.run(\n",
    "    code=\"build_resnet50_trt.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=\"resnet50.onnx\",\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            source=\"/opt/ml/processing/output\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f020fbf4-66d8-42ff-9fc2-6422c4fdddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-648758970526/tensorrt-2025-12-14-01-12-29-276/output/output-1/resnet50.trt to ./resnet50.trt\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp \\\n",
    "s3://sagemaker-us-east-1-648758970526/tensorrt-2025-12-14-01-12-29-276/output/output-1/resnet50.trt \\\n",
    "./resnet50.trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd0b2311-03ef-40cc-92e6-fa9e45bb39ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-14 01:38:54--  https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 661378 (646K) [image/jpeg]\n",
      "Saving to: ‘dog.jpg’\n",
      "\n",
      "100%[======================================>] 661,378     --.-K/s   in 0.007s  \n",
      "\n",
      "2025-12-14 01:38:54 (96.6 MB/s) - ‘dog.jpg’ saved [661378/661378]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O dog.jpg https://raw.githubusercontent.com/pytorch/hub/master/images/dog.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f13bca7d-8ea3-4378-8de9-215d0d4e1477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run_resnet50_trt_infer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_resnet50_trt_infer.py\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "engine_path = \"/opt/ml/processing/input/model/resnet50.trt\"\n",
    "image_path = \"/opt/ml/processing/input/image/dog.jpg\"\n",
    "\n",
    "# Load engine\n",
    "with open(engine_path, \"rb\") as f:\n",
    "    engine = trt.Runtime(TRT_LOGGER).deserialize_cuda_engine(f.read())\n",
    "\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# Load & preprocess image\n",
    "img = Image.open(image_path).convert(\"RGB\")\n",
    "img = img.resize((224, 224))\n",
    "\n",
    "img = np.array(img).astype(np.float32) / 255.0\n",
    "img = (img - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
    "\n",
    "img = img.transpose(2, 0, 1)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = np.ascontiguousarray(img)\n",
    "\n",
    "# Buffers\n",
    "h_input = img.astype(np.float32)\n",
    "h_output = np.empty((1, 1000), dtype=np.float32)\n",
    "\n",
    "d_input = cuda.mem_alloc(h_input.nbytes)\n",
    "d_output = cuda.mem_alloc(h_output.nbytes)\n",
    "\n",
    "cuda.memcpy_htod(d_input, h_input)\n",
    "context.execute_v2([int(d_input), int(d_output)])\n",
    "cuda.memcpy_dtoh(h_output, d_output)\n",
    "\n",
    "pred = np.argmax(h_output, axis=1)[0]\n",
    "print(\"Predicted ImageNet Class ID:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfafd549-ecc3-494c-a00d-51ebafc0865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker:Creating processing-job with name tensorrt-2025-12-14-01-40-32-769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............\u001b[34mPredicted ImageNet Class ID: 258\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "processor = ScriptProcessor(\n",
    "    role=role,\n",
    "    image_uri=\"648758970526.dkr.ecr.us-east-1.amazonaws.com/tensorrt:24.02-py3\",\n",
    "    command=[\"python3\"],\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    volume_size_in_gb=30,\n",
    "    max_runtime_in_seconds=600,\n",
    ")\n",
    "\n",
    "processor.run(\n",
    "    code=\"run_resnet50_trt_infer.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=\"resnet50.trt\",\n",
    "            destination=\"/opt/ml/processing/input/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=\"dog.jpg\",\n",
    "            destination=\"/opt/ml/processing/input/image\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82e49ad0-726b-44fc-aa47-e402a0cb28fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trt_timing_resnet50.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trt_timing_resnet50.py\n",
    "import time\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "\n",
    "ENGINE_PATH = \"/opt/ml/processing/input/model/resnet50.trt\"\n",
    "IMAGE_PATH = \"/opt/ml/processing/input/image/dog.jpg\"\n",
    "\n",
    "# -------------------------\n",
    "# Load TensorRT engine\n",
    "# -------------------------\n",
    "with open(ENGINE_PATH, \"rb\") as f:\n",
    "    engine = trt.Runtime(TRT_LOGGER).deserialize_cuda_engine(f.read())\n",
    "\n",
    "context = engine.create_execution_context()\n",
    "\n",
    "# -------------------------\n",
    "# Load & preprocess image\n",
    "# -------------------------\n",
    "img = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
    "img = img.resize((224, 224))\n",
    "\n",
    "img = np.array(img).astype(np.float32) / 255.0\n",
    "img = (img - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]\n",
    "img = img.transpose(2, 0, 1)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = np.ascontiguousarray(img)\n",
    "\n",
    "# -------------------------\n",
    "# Allocate buffers\n",
    "# -------------------------\n",
    "h_input = img.astype(np.float32)\n",
    "h_output = np.empty((1, 1000), dtype=np.float32)\n",
    "\n",
    "d_input = cuda.mem_alloc(h_input.nbytes)\n",
    "d_output = cuda.mem_alloc(h_output.nbytes)\n",
    "\n",
    "# -------------------------\n",
    "# Warm-up\n",
    "# -------------------------\n",
    "for _ in range(20):\n",
    "    cuda.memcpy_htod(d_input, h_input)\n",
    "    context.execute_v2([int(d_input), int(d_output)])\n",
    "    cuda.memcpy_dtoh(h_output, d_output)\n",
    "\n",
    "cuda.Context.synchronize()\n",
    "\n",
    "# -------------------------\n",
    "# Timing\n",
    "# -------------------------\n",
    "ITERATIONS = 200\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(ITERATIONS):\n",
    "    cuda.memcpy_htod(d_input, h_input)\n",
    "    context.execute_v2([int(d_input), int(d_output)])\n",
    "    cuda.memcpy_dtoh(h_output, d_output)\n",
    "\n",
    "cuda.Context.synchronize()\n",
    "elapsed = time.time() - start\n",
    "\n",
    "avg_ms = (elapsed / ITERATIONS) * 1000\n",
    "\n",
    "print(f\"TensorRT Average Inference Time: {avg_ms:.3f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0103b2f-668b-4b05-8ac9-371fac020146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker:Creating processing-job with name tensorrt-2025-12-14-01-49-43-493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........."
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "processor = ScriptProcessor(\n",
    "    role=role,\n",
    "    image_uri=\"648758970526.dkr.ecr.us-east-1.amazonaws.com/tensorrt:24.02-py3\",\n",
    "    command=[\"python3\"],\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    volume_size_in_gb=30,\n",
    "    max_runtime_in_seconds=600,\n",
    ")\n",
    "\n",
    "processor.run(\n",
    "    code=\"trt_timing_resnet50.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(source=\"resnet50.trt\", destination=\"/opt/ml/processing/input/model\"),\n",
    "        ProcessingInput(source=\"dog.jpg\", destination=\"/opt/ml/processing/input/image\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e015c02d",
   "metadata": {},
   "source": [
    "...............\n",
    "TensorRT Average Inference Time: 0.725 ms\n",
    "Pytorch Inference Time: 5.4 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8804015f-9782-4e8a-bbb4-716f68439c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
